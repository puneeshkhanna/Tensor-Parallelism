{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdN03X8dMGFl/k571aHI4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puneeshkhanna/Tensor-Parallelism/blob/master/tensor_parallelism_attention_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7Pl8o6JNBXvL"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input of dimensions (batch size, no of words, embedding dimension or hidden size of each word)\n",
        "input = torch.randn(size=(1, 5, 32), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "Td1StIsVCldQ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bsz, q_len, hidden_size = input.size()\n",
        "hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2ZqB8YLTnWI",
        "outputId": "500dda8d-37bc-42c3-f1a7-1e18ace5d14a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads = 4\n",
        "head_dim = hidden_size // num_heads\n",
        "head_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCHcWBKFTeQ4",
        "outputId": "1937f5c0-a9e5-489c-f53d-4319417837fb"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Layer output\n",
        "\n",
        "Tranformer architectures have Attention block with QKV layers followed by an o_proj (dense layer)\n",
        "\n",
        "```\n",
        "Attention(\n",
        "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "        )\n",
        "```"
      ],
      "metadata": {
        "id": "zdTszgCgW1zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_proj = nn.Linear(hidden_size, num_heads * head_dim, bias=False)\n",
        "k_proj = nn.Linear(hidden_size, num_heads * head_dim, bias=False)\n",
        "v_proj = nn.Linear(hidden_size, num_heads * head_dim, bias=False)\n",
        "\n",
        "o_proj = nn.Linear(num_heads * head_dim, hidden_size, bias=False)"
      ],
      "metadata": {
        "id": "SkVpKZr7BcCm"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_states = q_proj(input)\n",
        "key_states = k_proj(input)\n",
        "value_states = v_proj(input)\n",
        "\n",
        "query_states = query_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "key_states = key_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "value_states = value_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "query_states.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMDkkiqACDmd",
        "outputId": "a1ed4eac-b1e4-49eb-834b-d55e79a14d29"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 5, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
        "\n",
        "attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
        "\n",
        "attn_output = torch.matmul(attn_weights, value_states)\n",
        "\n",
        "attn_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1VgryJ3U08_",
        "outputId": "d04a7609-c4e0-4f1e-9f3e-80bf9fb9d32a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 5, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "\n",
        "attn_output = attn_output.reshape(bsz, q_len, hidden_size)\n",
        "\n",
        "attn_output_non_tp = o_proj(attn_output)\n",
        "\n",
        "attn_output_non_tp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B63TpefwVMGp",
        "outputId": "73d66357-dfb6-4698-9966-6ca3547ac364"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention layer output with Tensor parallelism\n",
        "\n",
        "Assuming 2 devices, below code depicts how weights will be divided between the 2 devices.\n",
        "\n",
        "Note that all the below code is executed on single device only with comments that which blocks will be executed on first device or second device."
      ],
      "metadata": {
        "id": "rINCD0tnWsFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_devices = 2\n",
        "num_heads = num_heads // n_devices\n",
        "hidden_size = hidden_size // n_devices\n",
        "print(num_heads, hidden_size)"
      ],
      "metadata": {
        "id": "z871j0n6UijU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97686ed-9f5c-4a55-991b-d16e71f0fff6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_slices = q_proj.weight.split(num_heads * head_dim, dim=0)\n",
        "\n",
        "key_slices = k_proj.weight.split(num_heads * head_dim, dim=0)\n",
        "\n",
        "value_slices = v_proj.weight.split(num_heads * head_dim, dim=0)\n",
        "\n",
        "o_proj_slices = o_proj.weight.split(num_heads * head_dim, dim=1)"
      ],
      "metadata": {
        "id": "-CoFzLL8XCyT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(q_proj.weight.shape, query_slices[0].shape, query_slices[1].shape)\n",
        "\n",
        "print(o_proj.weight.shape, o_proj_slices[0].shape, o_proj_slices[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DrBkdTFs8sA",
        "outputId": "ea136f47-d6b2-480a-b7ef-c1503ee6cdb5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 32]) torch.Size([16, 32]) torch.Size([16, 32])\n",
            "torch.Size([32, 32]) torch.Size([32, 16]) torch.Size([32, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First device - attention output logic"
      ],
      "metadata": {
        "id": "mnzBoHpRUT5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_states = F.linear(input, query_slices[0])\n",
        "\n",
        "key_states = F.linear(input, key_slices[0])\n",
        "\n",
        "value_states = F.linear(input, value_slices[0])\n",
        "\n",
        "query_states = query_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "key_states = key_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "value_states = value_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "query_states.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu5a_7vnCP4c",
        "outputId": "9cd968c1-cccb-466b-e479-73ba05f4d54c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 5, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
        "\n",
        "attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
        "\n",
        "attn_output = torch.matmul(attn_weights, value_states)\n",
        "\n",
        "attn_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJQZB4XJX4NM",
        "outputId": "f695d420-6e74-440a-a79e-ecfc4a18386d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 5, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "\n",
        "attn_output = attn_output.reshape(bsz, q_len, hidden_size)\n",
        "\n",
        "attn_output_1 = F.linear(attn_output, o_proj_slices[0])"
      ],
      "metadata": {
        "id": "Kiviet3gX5Bl"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second device - attention output logic"
      ],
      "metadata": {
        "id": "-GGjyS7AUae4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_states = F.linear(input, query_slices[1])\n",
        "\n",
        "key_states = F.linear(input, key_slices[1])\n",
        "\n",
        "value_states = F.linear(input, value_slices[1])\n",
        "\n",
        "query_states = query_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "key_states = key_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "value_states = value_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)"
      ],
      "metadata": {
        "id": "1K-W6FiGEj8Q"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
        "\n",
        "attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
        "\n",
        "attn_output = torch.matmul(attn_weights, value_states)"
      ],
      "metadata": {
        "id": "X4YjmSBoTEIu"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "\n",
        "attn_output = attn_output.reshape(bsz, q_len, hidden_size)\n",
        "\n",
        "attn_output_2 = F.linear(attn_output, o_proj_slices[1])"
      ],
      "metadata": {
        "id": "cUzzjciyYuLs"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add tensor parallel outputs of attn_output using torch.add; it will be an all reduce operation when using actual 2 devices"
      ],
      "metadata": {
        "id": "3ao8emKqUmgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In actual tensor parallelism between 2 devices, this will be all reduce operation\n",
        "attn_output_tp = torch.add(attn_output_1, attn_output_2)\n",
        "attn_output_tp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcT8l7QGKpuO",
        "outputId": "b87b3b4b-61b2-4f9b-c0c1-b62743292cea"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare final_output and final_output_tp using allclose"
      ],
      "metadata": {
        "id": "0Be7wx4XWowO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.allclose(attn_output_non_tp, attn_output_tp, rtol=1e-05, atol=1e-05))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef3Ll13rIc6A",
        "outputId": "6c62e4d9-de28-471b-a751-67606041d05e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output_non_tp"
      ],
      "metadata": {
        "id": "51vlAHWkJHN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce23c73-482d-4143-ebf5-ce7c7bd7d99b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4250, -0.0481,  0.1116, -0.1460, -0.3481, -0.1828, -0.0176,\n",
              "           0.1101, -0.0424,  0.0251,  0.0632,  0.0177, -0.1264,  0.0059,\n",
              "           0.1619, -0.2412,  0.1473, -0.0929,  0.1656, -0.0315, -0.1305,\n",
              "          -0.0577,  0.2283, -0.3891, -0.2213, -0.2125, -0.0287, -0.0260,\n",
              "          -0.2675, -0.0463, -0.0470, -0.0351],\n",
              "         [ 0.3329, -0.1350,  0.1774, -0.1266, -0.3457, -0.1331,  0.0591,\n",
              "           0.1060, -0.1679,  0.0124,  0.1157,  0.0533, -0.1115, -0.0017,\n",
              "           0.1772, -0.2066,  0.1702, -0.1749,  0.2329,  0.0469, -0.1127,\n",
              "          -0.2003,  0.3471, -0.4370, -0.1605, -0.2053, -0.0667, -0.0485,\n",
              "          -0.2776,  0.0339, -0.0089, -0.0604],\n",
              "         [ 0.3094, -0.1319,  0.0992, -0.0496, -0.3021, -0.1464,  0.0567,\n",
              "           0.0253,  0.0236, -0.0088,  0.0708, -0.0748, -0.2009, -0.0122,\n",
              "           0.0542, -0.2259,  0.2555, -0.1405,  0.1925, -0.0574, -0.1862,\n",
              "          -0.0678,  0.3356, -0.4476, -0.1952, -0.2065, -0.0017,  0.0199,\n",
              "          -0.2879,  0.0167, -0.0255, -0.1601],\n",
              "         [ 0.3498,  0.0115,  0.0855, -0.1512, -0.3864, -0.0815,  0.0010,\n",
              "           0.0046, -0.0526, -0.0630,  0.1515,  0.0141, -0.1945, -0.0869,\n",
              "           0.1576, -0.0820,  0.1690, -0.2251,  0.3564,  0.0463, -0.0728,\n",
              "          -0.0961,  0.2652, -0.3834, -0.1362, -0.1287, -0.1094,  0.0252,\n",
              "          -0.3119,  0.0657,  0.0353,  0.0612],\n",
              "         [ 0.4349,  0.1486,  0.0850, -0.2249, -0.5145, -0.1396, -0.0072,\n",
              "           0.0326, -0.0367, -0.0854,  0.1625,  0.0267, -0.1636, -0.1344,\n",
              "           0.1386, -0.1524,  0.1146, -0.2029,  0.2920,  0.0188, -0.0575,\n",
              "          -0.0549,  0.2031, -0.4398, -0.2630, -0.1791, -0.1878,  0.0781,\n",
              "          -0.3057, -0.0232, -0.0790, -0.0145]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output_tp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SFJUEqKWIaS",
        "outputId": "6fd33c91-c88b-45bc-8739-23144d2df086"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4250, -0.0481,  0.1116, -0.1460, -0.3481, -0.1828, -0.0176,\n",
              "           0.1101, -0.0424,  0.0251,  0.0632,  0.0177, -0.1264,  0.0059,\n",
              "           0.1619, -0.2412,  0.1473, -0.0929,  0.1656, -0.0315, -0.1305,\n",
              "          -0.0577,  0.2283, -0.3891, -0.2213, -0.2125, -0.0287, -0.0260,\n",
              "          -0.2675, -0.0463, -0.0470, -0.0351],\n",
              "         [ 0.3329, -0.1350,  0.1774, -0.1266, -0.3457, -0.1331,  0.0591,\n",
              "           0.1060, -0.1679,  0.0124,  0.1157,  0.0533, -0.1115, -0.0017,\n",
              "           0.1772, -0.2066,  0.1702, -0.1749,  0.2329,  0.0469, -0.1127,\n",
              "          -0.2003,  0.3471, -0.4370, -0.1605, -0.2053, -0.0667, -0.0485,\n",
              "          -0.2776,  0.0339, -0.0089, -0.0604],\n",
              "         [ 0.3094, -0.1319,  0.0992, -0.0496, -0.3021, -0.1464,  0.0567,\n",
              "           0.0253,  0.0236, -0.0088,  0.0708, -0.0748, -0.2009, -0.0122,\n",
              "           0.0542, -0.2259,  0.2555, -0.1405,  0.1925, -0.0574, -0.1862,\n",
              "          -0.0678,  0.3356, -0.4476, -0.1952, -0.2065, -0.0017,  0.0199,\n",
              "          -0.2879,  0.0167, -0.0255, -0.1601],\n",
              "         [ 0.3498,  0.0115,  0.0855, -0.1512, -0.3864, -0.0815,  0.0010,\n",
              "           0.0046, -0.0526, -0.0630,  0.1515,  0.0141, -0.1945, -0.0869,\n",
              "           0.1576, -0.0820,  0.1690, -0.2251,  0.3564,  0.0463, -0.0728,\n",
              "          -0.0961,  0.2652, -0.3834, -0.1362, -0.1287, -0.1094,  0.0252,\n",
              "          -0.3119,  0.0657,  0.0353,  0.0612],\n",
              "         [ 0.4349,  0.1486,  0.0850, -0.2249, -0.5145, -0.1396, -0.0072,\n",
              "           0.0326, -0.0367, -0.0854,  0.1625,  0.0267, -0.1636, -0.1344,\n",
              "           0.1386, -0.1524,  0.1146, -0.2029,  0.2920,  0.0188, -0.0575,\n",
              "          -0.0549,  0.2031, -0.4398, -0.2630, -0.1791, -0.1878,  0.0781,\n",
              "          -0.3057, -0.0232, -0.0790, -0.0145]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fRIL27ZDWL0J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}