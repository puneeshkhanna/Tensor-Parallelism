{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUSgotXxojnb4KEFnB03My",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puneeshkhanna/Tensor-Parallelism/blob/master/tensor_parallelism_attention_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "7Pl8o6JNBXvL"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input of dimensions (batch size, no of words or q_len, embedding dimension or hidden size of each word)\n",
        "input = torch.randn(size=(1, 5, 32), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "Td1StIsVCldQ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bsz, q_len, hidden_size = input.size()\n",
        "hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2ZqB8YLTnWI",
        "outputId": "cd7edef4-1c62-4c71-fa51-63597c4fa260"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of attention heads of multi head attention of each transformer block\n",
        "num_heads = 4\n",
        "\n",
        "# hidden size is divisible by num heads; per head embedding dim\n",
        "head_dim = hidden_size // num_heads\n",
        "\n",
        "print(f\"num heads is {num_heads}, hidden size is {hidden_size}, head dim is {head_dim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCHcWBKFTeQ4",
        "outputId": "437501f2-0011-4bcd-f83d-c192f2b67fb4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num heads is 4, hidden size is 32, head dim is 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Layer output\n",
        "\n",
        "Tranformer architectures have Attention block with QKV layers followed by an o_proj (dense layer)\n",
        "\n",
        "```\n",
        "Attention(\n",
        "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
        "        )\n",
        "```"
      ],
      "metadata": {
        "id": "zdTszgCgW1zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_proj = nn.Linear(hidden_size, num_heads * head_dim, bias=False)\n",
        "k_proj = nn.Linear(hidden_size, num_heads * head_dim, bias=False)\n",
        "v_proj = nn.Linear(hidden_size, num_heads * head_dim, bias=False)\n",
        "\n",
        "o_proj = nn.Linear(num_heads * head_dim, hidden_size, bias=False)\n",
        "\n",
        "print(\"q_proj weights shape:\", q_proj.weight.shape)\n",
        "print(\"o_proj weights shape:\", o_proj.weight.shape)"
      ],
      "metadata": {
        "id": "SkVpKZr7BcCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba537da0-bafc-484b-ad22-126d7ade9047"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q_proj weights shape: torch.Size([32, 32])\n",
            "o_proj weights shape: torch.Size([32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_states = q_proj(input)\n",
        "key_states = k_proj(input)\n",
        "value_states = v_proj(input)\n",
        "\n",
        "print(\"query_states after projections -> [batch size, q_len, num heads*head_dim]: \", query_states.shape)\n",
        "\n",
        "query_states = query_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "key_states = key_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "value_states = value_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "print(\"\\nquery_states after view and transpose -> [batch size, num heads, q_len, head_dim]:\", query_states.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMDkkiqACDmd",
        "outputId": "77986077-4d1e-4351-b158-2f77223255ef"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_states after projections -> [batch size, q_len, num heads*head_dim]:  torch.Size([1, 5, 32])\n",
            "\n",
            "query_states after view and transpose -> [batch size, num heads, q_len, head_dim]: torch.Size([1, 4, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
        "attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
        "print(\"attn matrix after QK.T and softmax -> [batch size, num heads, q_len, q_len]:\", attn_weights.shape)\n",
        "\n",
        "attn_output = torch.matmul(attn_weights, value_states)\n",
        "print(\"\\nattn output -> matmul of attn matrix [batch size, num heads, q_len, q_len] and value states [batch size, num heads, q_len, head_dim] -> [batch size, num heads, q_len, head_dim]:\", attn_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1VgryJ3U08_",
        "outputId": "ad2ebd19-47b0-4804-bbf9-35ecac8bbd55"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attn matrix after QK.T and softmax -> [batch size, num heads, q_len, q_len]: torch.Size([1, 4, 5, 5])\n",
            "\n",
            "attn output -> matmul of attn matrix [batch size, num heads, q_len, q_len] and value states [batch size, num heads, q_len, head_dim] -> [batch size, num heads, q_len, head_dim]: torch.Size([1, 4, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "attn_output = attn_output.reshape(bsz, q_len, num_heads*head_dim)\n",
        "print(\"attn output after view and reshape -> [batch size, q_len, num heads*head_dim]:\", attn_output.shape)\n",
        "\n",
        "attn_output_non_tp = o_proj(attn_output)\n",
        "print(\"\\nattn output after final o_proj -> [batch size, q_len, hidden_size]:\", attn_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B63TpefwVMGp",
        "outputId": "37cc6f11-e265-4fbb-ce5b-54ca0d81b178"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attn output after view and reshape -> [batch size, q_len, num heads*head_dim]: torch.Size([1, 5, 32])\n",
            "\n",
            "attn output after final o_proj -> [batch size, q_len, hidden_size]: torch.Size([1, 5, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention layer output with Tensor parallelism\n",
        "\n",
        "Assuming 2 devices, below code depicts how attention heads will be divided between the 2 devices.\n",
        "\n",
        "Note that all the below code is executed on single device only with comments that which blocks will be executed on first device or second device."
      ],
      "metadata": {
        "id": "rINCD0tnWsFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_devices = 2\n",
        "num_heads = num_heads // n_devices\n",
        "print(f\"num heads changes to {num_heads}\")"
      ],
      "metadata": {
        "id": "z871j0n6UijU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0542ae49-b56c-476f-e7b8-9742c6ed810b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num heads changes to 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dividing q_proj, k_proj, v_proj, o_proj weights based upon num_heads\")\n",
        "\n",
        "query_slices = q_proj.weight.split(num_heads * head_dim, dim=0)\n",
        "key_slices = k_proj.weight.split(num_heads * head_dim, dim=0)\n",
        "value_slices = v_proj.weight.split(num_heads * head_dim, dim=0)\n",
        "\n",
        "o_proj_slices = o_proj.weight.split(num_heads * head_dim, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CoFzLL8XCyT",
        "outputId": "0621651a-294e-4eb3-b445-86e7c5810ab3"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dividing q_proj, k_proj, v_proj, o_proj weights based upon num_heads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original qkv proj weights transpose without TP:\",q_proj.weight.T.shape, \"\\tPer device qkv proj weights transpose with TP (column divided):\", query_slices[0].T.shape)\n",
        "\n",
        "print(\"\\nOriginal o_proj weights transpose without TP:\",o_proj.weight.T.shape, \"\\tPer device o_proj weights transpose with TP (row divided):\", o_proj_slices[0].T.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DrBkdTFs8sA",
        "outputId": "154e2442-2a56-4789-8596-106b77095b45"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original qkv proj weights transpose without TP: torch.Size([32, 32]) \tPer device qkv proj weights transpose with TP (column divided): torch.Size([32, 16])\n",
            "\n",
            "Original o_proj weights transpose without TP: torch.Size([32, 32]) \tPer device o_proj weights transpose with TP (row divided): torch.Size([16, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First device - attention output logic"
      ],
      "metadata": {
        "id": "mnzBoHpRUT5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_states = F.linear(input, query_slices[0])\n",
        "key_states = F.linear(input, key_slices[0])\n",
        "value_states = F.linear(input, value_slices[0])\n",
        "\n",
        "print(\"query_states after projections -> [batch size, q_len, num heads*head_dim]: \", query_states.shape)\n",
        "\n",
        "query_states = query_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "key_states = key_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "value_states = value_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "print(\"\\nquery_states after view and transpose -> [batch size, num heads, q_len, head_dim]:\", query_states.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu5a_7vnCP4c",
        "outputId": "5be14496-fa4c-4e92-ed2a-80d23185cd13"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_states after projections -> [batch size, q_len, num heads*head_dim]:  torch.Size([1, 5, 16])\n",
            "\n",
            "query_states after view and transpose -> [batch size, num heads, q_len, head_dim]: torch.Size([1, 2, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
        "attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
        "print(\"attn matrix after QK.T and softmax -> [batch size, num heads, q_len, q_len]:\", attn_weights.shape)\n",
        "\n",
        "attn_output = torch.matmul(attn_weights, value_states)\n",
        "print(\"\\nattn output -> matmul of attn matrix [batch size, num heads, q_len, q_len] and value states [batch size, num heads, q_len, head_dim] -> [batch size, num heads, q_len, head_dim]:\", attn_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJQZB4XJX4NM",
        "outputId": "cb452abc-4658-4714-c07d-90ecf71f9fe0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attn matrix after QK.T and softmax -> [batch size, num heads, q_len, q_len]: torch.Size([1, 2, 5, 5])\n",
            "\n",
            "attn output -> matmul of attn matrix [batch size, num heads, q_len, q_len] and value states [batch size, num heads, q_len, head_dim] -> [batch size, num heads, q_len, head_dim]: torch.Size([1, 2, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "attn_output = attn_output.reshape(bsz, q_len, num_heads*head_dim)\n",
        "print(\"attn output after view and reshape -> [batch size, q_len, num heads*head_dim]:\", attn_output.shape)\n",
        "\n",
        "attn_output_1 = F.linear(attn_output, o_proj_slices[0])\n",
        "print(\"\\nattn output on 1st Tensor Parallel device after final o_proj -> [batch size, q_len, hidden_size]:\", attn_output_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiviet3gX5Bl",
        "outputId": "3bb60cfa-99c5-4e04-8b94-908d8bddcb54"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attn output after view and reshape -> [batch size, q_len, num heads*head_dim]: torch.Size([1, 5, 16])\n",
            "\n",
            "attn output on 1st Tensor Parallel device after final o_proj -> [batch size, q_len, hidden_size]: torch.Size([1, 5, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second device - attention output logic"
      ],
      "metadata": {
        "id": "-GGjyS7AUae4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_states = F.linear(input, query_slices[1])\n",
        "key_states = F.linear(input, key_slices[1])\n",
        "value_states = F.linear(input, value_slices[1])\n",
        "print(\"query_states after projections -> [batch size, q_len, num heads*head_dim]: \", query_states.shape)\n",
        "\n",
        "query_states = query_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "key_states = key_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "value_states = value_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
        "print(\"\\nquery_states after view and transpose -> [batch size, num heads, q_len, head_dim]:\", query_states.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K-W6FiGEj8Q",
        "outputId": "caab7dca-bdbb-4a4d-eecd-52475974aa2d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_states after projections -> [batch size, q_len, num heads*head_dim]:  torch.Size([1, 5, 16])\n",
            "\n",
            "query_states after view and transpose -> [batch size, num heads, q_len, head_dim]: torch.Size([1, 2, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
        "attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
        "print(\"attn matrix after QK.T and softmax -> [batch size, num heads, q_len, q_len]:\", attn_weights.shape)\n",
        "\n",
        "attn_output = torch.matmul(attn_weights, value_states)\n",
        "print(\"\\nattn output -> matmul of attn matrix [batch size, num heads, q_len, q_len] and value states [batch size, num heads, q_len, head_dim] -> [batch size, num heads, q_len, head_dim]:\", attn_output.shape)"
      ],
      "metadata": {
        "id": "X4YjmSBoTEIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4320b7-73ea-44cf-89be-9a9d2aa9a736"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attn matrix after QK.T and softmax -> [batch size, num heads, q_len, q_len]: torch.Size([1, 2, 5, 5])\n",
            "\n",
            "attn output -> matmul of attn matrix [batch size, num heads, q_len, q_len] and value states [batch size, num heads, q_len, head_dim] -> [batch size, num heads, q_len, head_dim]: torch.Size([1, 2, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "attn_output = attn_output.reshape(bsz, q_len, num_heads*head_dim)\n",
        "print(\"attn output after view and reshape -> [batch size, q_len, num heads*head_dim]:\", attn_output.shape)\n",
        "\n",
        "attn_output_2 = F.linear(attn_output, o_proj_slices[1])\n",
        "print(\"\\nattn output on 2nd Tensor Parallel device after final o_proj -> [batch size, q_len, hidden_size]:\", attn_output_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUzzjciyYuLs",
        "outputId": "f09b7cdd-d622-42bc-9759-537a58a20229"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attn output after view and reshape -> [batch size, q_len, num heads*head_dim]: torch.Size([1, 5, 16])\n",
            "\n",
            "attn output on 2nd Tensor Parallel device after final o_proj -> [batch size, q_len, hidden_size]: torch.Size([1, 5, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add tensor parallel outputs of attn_output using torch.add; it will be an all reduce operation when using actual 2 devices"
      ],
      "metadata": {
        "id": "3ao8emKqUmgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In actual tensor parallelism between 2 devices, this will be all reduce operation\n",
        "attn_output_tp = torch.add(attn_output_1, attn_output_2)\n",
        "attn_output_tp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcT8l7QGKpuO",
        "outputId": "a8dfa5b0-7255-49e2-b3f2-ae2726fd097e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare final_output_non_tp and final_output_tp using allclose"
      ],
      "metadata": {
        "id": "0Be7wx4XWowO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.allclose(attn_output_non_tp, attn_output_tp, rtol=1e-05, atol=1e-05))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef3Ll13rIc6A",
        "outputId": "2a081a7b-5ba1-4b9f-845f-234af87a2658"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output_non_tp"
      ],
      "metadata": {
        "id": "51vlAHWkJHN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c45655-fcda-48cd-fee5-4cc7464a1d82"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.5638e-01,  3.2600e-01, -3.2392e-01,  3.5811e-01,  8.3697e-02,\n",
              "           3.7586e-01, -2.3411e-01, -3.1438e-01, -2.7816e-01,  1.7625e-01,\n",
              "           6.6336e-02, -2.1609e-02, -7.9867e-02,  4.6139e-03,  3.9733e-02,\n",
              "          -2.8644e-01, -3.2399e-02,  3.3861e-01, -1.2574e-01,  1.1643e-01,\n",
              "          -1.6354e-01, -1.6879e-01, -7.3738e-03, -1.1563e-01, -3.7473e-01,\n",
              "           1.0994e-01,  2.5477e-01,  2.8067e-01, -1.8519e-01, -2.6387e-01,\n",
              "          -4.0888e-01,  4.1851e-02],\n",
              "         [-3.3681e-01,  1.5425e-01, -3.6065e-01,  4.2199e-01,  2.5573e-02,\n",
              "           4.9650e-01, -2.8206e-01, -2.9998e-01, -3.5022e-01,  1.3859e-01,\n",
              "           8.8276e-03,  5.4824e-02, -1.7515e-01,  8.2978e-02,  8.6214e-02,\n",
              "          -3.4301e-01, -5.9058e-02,  3.6043e-01, -1.6147e-01,  4.5518e-02,\n",
              "          -1.6713e-01, -1.0388e-01, -3.5998e-02, -6.6658e-02, -3.3598e-01,\n",
              "           1.5457e-01,  3.3041e-01,  1.4448e-01, -1.4736e-01, -1.7590e-01,\n",
              "          -3.8984e-01,  1.5257e-02],\n",
              "         [-3.5187e-01,  2.8584e-02, -3.2784e-01,  3.4551e-01,  1.1050e-02,\n",
              "           5.0030e-01, -3.3799e-01, -3.3729e-01, -2.7769e-01,  1.7348e-01,\n",
              "           2.0212e-02,  9.6586e-02, -2.0309e-01,  4.8731e-02,  9.1335e-02,\n",
              "          -3.6785e-01, -6.8075e-02,  3.3865e-01, -1.4495e-01,  8.4706e-02,\n",
              "          -1.0647e-01, -9.8088e-02, -2.4342e-02, -8.6378e-02, -3.6998e-01,\n",
              "           1.4301e-01,  4.0547e-01,  8.8723e-02, -1.3382e-01, -1.3384e-01,\n",
              "          -2.8186e-01,  1.3583e-02],\n",
              "         [-4.9356e-01,  1.0948e-01, -3.3067e-01,  2.5804e-01,  1.4601e-01,\n",
              "           5.0660e-01, -2.0223e-01, -3.8028e-01, -3.8972e-01,  1.6487e-01,\n",
              "           1.8222e-01,  1.2948e-01, -3.5689e-02,  2.1622e-01,  6.1272e-02,\n",
              "          -2.9290e-01, -4.5781e-02,  3.8281e-01, -1.7363e-01,  1.5133e-01,\n",
              "          -2.0141e-01, -1.4376e-01, -2.3620e-02, -4.0567e-02, -2.9135e-01,\n",
              "           1.3300e-01,  2.4475e-01,  1.4728e-01, -2.0445e-01, -2.8388e-01,\n",
              "          -4.6744e-01, -6.1215e-02],\n",
              "         [-3.1269e-01,  1.1854e-01, -3.1881e-01,  2.4660e-01,  4.5769e-02,\n",
              "           5.0134e-01, -2.4016e-01, -3.2593e-01, -1.9452e-01,  9.2601e-02,\n",
              "           1.2878e-01,  1.4411e-01, -2.0216e-02,  7.8152e-02, -8.6003e-03,\n",
              "          -3.7269e-01, -7.1656e-02,  3.2733e-01, -9.6797e-02,  1.2378e-01,\n",
              "          -1.9054e-01, -2.0037e-01, -6.9454e-02, -1.0122e-04, -2.4750e-01,\n",
              "           1.5464e-01,  2.6320e-01,  7.5485e-02, -1.3148e-01, -1.6346e-01,\n",
              "          -4.8032e-01, -7.9458e-02]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output_tp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SFJUEqKWIaS",
        "outputId": "7e770816-a77d-49cb-845a-3127151d1cce"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.5638e-01,  3.2600e-01, -3.2392e-01,  3.5811e-01,  8.3697e-02,\n",
              "           3.7586e-01, -2.3411e-01, -3.1438e-01, -2.7816e-01,  1.7625e-01,\n",
              "           6.6336e-02, -2.1609e-02, -7.9867e-02,  4.6139e-03,  3.9733e-02,\n",
              "          -2.8644e-01, -3.2399e-02,  3.3861e-01, -1.2574e-01,  1.1643e-01,\n",
              "          -1.6354e-01, -1.6879e-01, -7.3738e-03, -1.1563e-01, -3.7473e-01,\n",
              "           1.0994e-01,  2.5477e-01,  2.8067e-01, -1.8519e-01, -2.6387e-01,\n",
              "          -4.0888e-01,  4.1851e-02],\n",
              "         [-3.3681e-01,  1.5425e-01, -3.6065e-01,  4.2199e-01,  2.5573e-02,\n",
              "           4.9650e-01, -2.8206e-01, -2.9998e-01, -3.5022e-01,  1.3859e-01,\n",
              "           8.8276e-03,  5.4824e-02, -1.7515e-01,  8.2978e-02,  8.6214e-02,\n",
              "          -3.4301e-01, -5.9058e-02,  3.6043e-01, -1.6147e-01,  4.5518e-02,\n",
              "          -1.6713e-01, -1.0388e-01, -3.5998e-02, -6.6658e-02, -3.3598e-01,\n",
              "           1.5457e-01,  3.3041e-01,  1.4448e-01, -1.4736e-01, -1.7590e-01,\n",
              "          -3.8984e-01,  1.5257e-02],\n",
              "         [-3.5187e-01,  2.8584e-02, -3.2784e-01,  3.4551e-01,  1.1050e-02,\n",
              "           5.0030e-01, -3.3799e-01, -3.3729e-01, -2.7769e-01,  1.7348e-01,\n",
              "           2.0212e-02,  9.6586e-02, -2.0309e-01,  4.8731e-02,  9.1335e-02,\n",
              "          -3.6785e-01, -6.8075e-02,  3.3865e-01, -1.4495e-01,  8.4706e-02,\n",
              "          -1.0647e-01, -9.8088e-02, -2.4342e-02, -8.6378e-02, -3.6998e-01,\n",
              "           1.4301e-01,  4.0547e-01,  8.8723e-02, -1.3382e-01, -1.3384e-01,\n",
              "          -2.8186e-01,  1.3583e-02],\n",
              "         [-4.9356e-01,  1.0948e-01, -3.3067e-01,  2.5804e-01,  1.4601e-01,\n",
              "           5.0660e-01, -2.0223e-01, -3.8028e-01, -3.8972e-01,  1.6487e-01,\n",
              "           1.8222e-01,  1.2948e-01, -3.5689e-02,  2.1622e-01,  6.1272e-02,\n",
              "          -2.9290e-01, -4.5781e-02,  3.8281e-01, -1.7363e-01,  1.5133e-01,\n",
              "          -2.0141e-01, -1.4376e-01, -2.3620e-02, -4.0567e-02, -2.9135e-01,\n",
              "           1.3300e-01,  2.4475e-01,  1.4728e-01, -2.0445e-01, -2.8388e-01,\n",
              "          -4.6744e-01, -6.1215e-02],\n",
              "         [-3.1269e-01,  1.1854e-01, -3.1881e-01,  2.4660e-01,  4.5769e-02,\n",
              "           5.0134e-01, -2.4016e-01, -3.2593e-01, -1.9452e-01,  9.2601e-02,\n",
              "           1.2878e-01,  1.4411e-01, -2.0216e-02,  7.8152e-02, -8.6003e-03,\n",
              "          -3.7269e-01, -7.1656e-02,  3.2733e-01, -9.6797e-02,  1.2378e-01,\n",
              "          -1.9054e-01, -2.0037e-01, -6.9454e-02, -1.0121e-04, -2.4750e-01,\n",
              "           1.5464e-01,  2.6320e-01,  7.5485e-02, -1.3148e-01, -1.6346e-01,\n",
              "          -4.8032e-01, -7.9458e-02]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woxb19mkaI24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}